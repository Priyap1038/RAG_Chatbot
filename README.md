# ü§ñ RAG Chatbot ‚Äî Acme Tech Solutions

A production-ready **Retrieval-Augmented Generation (RAG) Chatbot** built with:

- üêç **Backend** ‚Äî FastAPI + LangChain + Pinecone (vector search) + SQLite (chat history)
- ‚öõÔ∏è **Frontend** ‚Äî React 19 + Vite + Tailwind CSS

---

## üìÅ Project Structure

```
RAG_Chatbot/
‚îú‚îÄ‚îÄ rag_chatbot/          # Python FastAPI backend
‚îÇ   ‚îú‚îÄ‚îÄ routes/           # API route handlers (chat, history, session, ingest)
‚îÇ   ‚îú‚îÄ‚îÄ middleware/        # Auth middleware
‚îÇ   ‚îú‚îÄ‚îÄ docs/             # Source documents for RAG ingestion
‚îÇ   ‚îú‚îÄ‚îÄ main.py           # FastAPI app entry point
‚îÇ   ‚îú‚îÄ‚îÄ config.py         # Configuration (reads .env)
‚îÇ   ‚îú‚îÄ‚îÄ vectorstore.py    # Pinecone vector store logic
‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py     # Embedding model setup
‚îÇ   ‚îú‚îÄ‚îÄ memory.py         # SQLite chat session management
‚îÇ   ‚îú‚îÄ‚îÄ ingestion.py      # Document ingestion pipeline
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt  # Python dependencies
‚îÇ   ‚îî‚îÄ‚îÄ .env.example      # Backend env template
‚îÇ
‚îú‚îÄ‚îÄ rag_frontend/         # React + Vite frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/   # ChatWindow, Sidebar, MessageBubble
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx       # Root component
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.js        # Axios API calls to backend
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.css     # Global styles
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ .env.example      # Frontend env template
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md
```

---

## ‚úÖ Prerequisites

Make sure you have the following installed:

| Tool | Version | Download |
|------|---------|----------|
| Python | ‚â• 3.10 | [python.org](https://python.org) |
| Node.js | ‚â• 18.x | [nodejs.org](https://nodejs.org) |
| Git | any | [git-scm.com](https://git-scm.com) |

You will also need accounts / API keys for:
- **Pinecone** ‚Äî [pinecone.io](https://pinecone.io) (free tier works)
- **OpenAI** (optional) ‚Äî [platform.openai.com](https://platform.openai.com) *(or use Ollama locally)*

---

## üöÄ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/Priyap1038/ChatBot.git
cd ChatBot
```

---

### 2. Backend Setup (`rag_chatbot/`)

#### a) Create a virtual environment

```bash
cd rag_chatbot

# Windows
python -m venv venv
venv\Scripts\activate

# macOS / Linux
python3 -m venv venv
source venv/bin/activate
```

#### b) Install dependencies

```bash
pip install -r requirements.txt
```

#### c) Configure environment variables

```bash
# Copy the example file
copy .env.example .env        # Windows
cp .env.example .env          # macOS / Linux
```

Now open `.env` and fill in your values:

```env
OPENAI_API_KEY=sk-...                   # Your OpenAI API key (if using OpenAI)
PINECONE_API_KEY=pcsk_...              # Your Pinecone API key
PINECONE_INDEX_NAME=priya-rag-index    # Your Pinecone index name
CORS_ORIGINS=*                         # Use * for local dev
RATE_LIMIT=30/minute
LOG_LEVEL=INFO
```

#### d) Ingest documents into Pinecone

> This step uploads your documents in `docs/` into the Pinecone vector store.
> Run this **once** before starting the server (or whenever you add new docs).

```bash
python ingest_docs.py
```

#### e) Start the backend server

```bash
uvicorn main:app --reload --port 8000
```

The API will be live at: **http://localhost:8000**

- Swagger UI: http://localhost:8000/docs
- Health check: http://localhost:8000/api/health

---

### 3. Frontend Setup (`rag_frontend/`)

Open a **new terminal** and run:

#### a) Install Node dependencies

```bash
cd rag_frontend
npm install
```

#### b) Configure environment variables

```bash
# Windows
copy .env.example .env

# macOS / Linux
cp .env.example .env
```

For local development, the default `.env` values work out of the box (Vite proxies `/api/*` ‚Üí `localhost:8000`):

```env
VITE_API_URL=       # Leave empty for local dev
VITE_API_KEY=       # Leave empty unless backend API_KEY is set
```

#### c) Start the frontend dev server

```bash
npm run dev
```

The app will be live at: **http://localhost:5173**

---

## üñ•Ô∏è Running Both Together (Quick Start)

Open **two terminals** side-by-side:

| Terminal 1 ‚Äî Backend | Terminal 2 ‚Äî Frontend |
|---|---|
| `cd rag_chatbot` | `cd rag_frontend` |
| `venv\Scripts\activate` | `npm install` |
| `uvicorn main:app --reload` | `npm run dev` |

Then open **http://localhost:5173** in your browser. üéâ

---

## üìÑ Adding Your Own Documents

1. Place your `.md`, `.txt`, or `.pdf` files inside `rag_chatbot/docs/`
2. Re-run the ingestion script:
   ```bash
   cd rag_chatbot
   python ingest_docs.py
   ```
3. Restart the backend server.

---

## üîå API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/health` | Health check |
| `GET` | `/api/sessions` | List all chat sessions |
| `POST` | `/api/chat` | Send a message |
| `GET` | `/api/history/{session_id}` | Get chat history for a session |
| `POST` | `/api/session` | Create a new session |
| `POST` | `/api/ingest` | Ingest a document via API |

Full interactive docs: **http://localhost:8000/docs**

---

## üèóÔ∏è Production Build (Frontend)

```bash
cd rag_frontend
npm run build
```

Output will be in `rag_frontend/dist/`. Serve it with any static host (Vercel, Netlify, etc.).

For the backend, update `.env`:
```env
CORS_ORIGINS=https://yourfrontend.com
API_KEY=your-strong-secret-key
```

---

## üõ†Ô∏è Troubleshooting

| Problem | Fix |
|---------|-----|
| `ModuleNotFoundError` | Make sure your venv is activated and `pip install -r requirements.txt` was run |
| Pinecone connection error | Double-check `PINECONE_API_KEY` and `PINECONE_INDEX_NAME` in `.env` |
| CORS errors in browser | Ensure `CORS_ORIGINS=*` is set in backend `.env` during development |
| Frontend can't reach backend | Make sure backend is running on port `8000` and frontend on `5173` |
| Port already in use | Use `--port 8001` flag: `uvicorn main:app --reload --port 8001` |

---

## üìú License

This project is for educational / internal use. Feel free to fork and adapt!
